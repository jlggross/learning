{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"merging-dataframes-with-pandas.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ftI0p3tboPwJnmgS8dZ58zkp651t5tKN","authorship_tag":"ABX9TyNtDDuv2zach/sCJ54cGji0"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jsbffugJSv5Y","colab_type":"text"},"source":["# Course: Merging DataFrames with pandas \n","\n","* Link: https://learn.datacamp.com/courses/merging-dataframes-with-pandas\n","* Datasets: https://www.data.gov/\n"]},{"cell_type":"markdown","metadata":{"id":"J3tn67lsAH_5","colab_type":"text"},"source":["## Course Description\n","\n","As a data scientist, you'll often find that the data you need is not in a single file. It may be spread across a number of text files, spreadsheets, or databases. You’ll want to be able to import the data you’re interested in as a collection of DataFrames and combine them to answer your central questions. This course is all about the act of combining—or merging—DataFrames, an essential part of any data scientist's toolbox. You'll hone your pandas skills by learning how to organize, reshape, and aggregate multiple datasets to answer your specific questions."]},{"cell_type":"markdown","metadata":{"id":"9pB9EK6JALyM","colab_type":"text"},"source":["# Chapter 1 - Preparing data\n","\n","In this chapter, you'll learn about different techniques you can use to import multiple files into DataFrames. Having imported your data into individual DataFrames, you'll then learn how to share information between DataFrames using their indexes. Understanding how indexes work is essential to merging DataFrames, which you’ll learn later in the course.\n"]},{"cell_type":"markdown","metadata":{"id":"P8EnsuO7ARP4","colab_type":"text"},"source":["## Reading multiple data files"]},{"cell_type":"markdown","metadata":{"id":"8ng1xiYEBPUr","colab_type":"text"},"source":["### Loading separate files"]},{"cell_type":"code","metadata":{"id":"FhHcO4QbA6xx","colab_type":"code","colab":{}},"source":["# Loading separate files\n","import pandas as pd\n","dataframe0 = pd.read_csv('sales-jan-2015.csv')\n","dataframe1 = pd.read_csv('sales-feb-2015.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OQ5s6f5CBSpZ","colab_type":"text"},"source":["### Using a loop"]},{"cell_type":"code","metadata":{"id":"ApKDQg85A07I","colab_type":"code","colab":{}},"source":["# Using a loop\n","filenames = ['sales-jan-2015.csv', 'sales-feb-2015.csv']\n","dataframes = []\n","for f in filenames:\n","    dataframes.append(pd.read_csv(f))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qA6Zka81BUFg","colab_type":"text"},"source":["### Using a comprehension"]},{"cell_type":"code","metadata":{"id":"cE6c8q6dBCZd","colab_type":"code","colab":{}},"source":["# Using a comprehension\n","filenames = ['sales-jan-2015.csv', 'sales-feb-2015.csv']\n","dataframes = [pd.read_csv(f) for f in filenames]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EuqnXH_XBWAQ","colab_type":"text"},"source":["### Using glob"]},{"cell_type":"code","metadata":{"id":"xmkxpZb1BID8","colab_type":"code","colab":{}},"source":["# Using glob\n","from glob import glob\n","\n","filenames = glob('sales*.csv')\n","dataframes = [pd.read_csv(f) for f in filenames"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gcupKnNPBadu","colab_type":"text"},"source":["## Reindexing DataFrames"]},{"cell_type":"markdown","metadata":{"id":"XvrtNHz5Bgml","colab_type":"text"},"source":["### \"Indexes\" vs. \"Indices\"\n","\n","* indices: many index labels within `Index` data structures\n","* indexes: many pandas `Index` data structures"]},{"cell_type":"markdown","metadata":{"id":"nq3B6o8CB5nZ","colab_type":"text"},"source":["### Importing weather data"]},{"cell_type":"code","metadata":{"id":"EGnrLja9TNEj","colab_type":"code","colab":{}},"source":["# --------------------------------------------------------------------------------------------------------\n","# Importing weather data\n","# --------------------------------------------------------------------------------------------------------\n","import pandas as pd\n","w_mean = pd.read_csv('quarterly_mean_temp.csv', index_col='Month')\n","w_max = pd.read_csv('quarterly_max_temp.csv', index_col='Month')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eue1WelaCAel","colab_type":"text"},"source":["### The DataFrame indexes"]},{"cell_type":"code","metadata":{"id":"lW2L1sOuT2ke","colab_type":"code","colab":{}},"source":["# The DataFrame indexes\n","\n","print(w_mean.index)\n","# > Index(['Apr', 'Jan', 'Jul', 'Oct'], dtype='object', name='Month')\n","\n","print(w_max.index)\n","# > Index(['Jan', 'Apr', 'Jul', 'Oct'], dtype='object', name='Month')\n","\n","print(type(w_mean.index))\n","# > <class 'pandas.indexes.base.Index'>\n","\n","# Rename column names\n","temps_f = weather[['Min TemperatureF', 'Mean TemperatureF', 'Max TemperatureF']]\n","temps_c = temps_f.copy()\n","temps_c.columns = temps_c.columns.str.replace('F', 'C') # 'Min TemperatureC', 'Mean TemperatureC', 'Max TemperatureC'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OUYA7HIhDbUH","colab_type":"text"},"source":["#### Setting multiple indexes"]},{"cell_type":"code","metadata":{"id":"fFmvBm_lbAm0","colab_type":"code","colab":{}},"source":["# Setting multiple indexes\n","names_1981 = pd.read_csv('names1981.csv', header=None, names=['name','gender','count'], index_col=(0,1)) # Set as indexes \"name\" and \"gender\"\n","names_1881 = pd.read_csv('names1881.csv', header=None, names=['name','gender','count'], index_col=(0,1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yJjN8do6CGX2","colab_type":"text"},"source":["### Using `.reindex()` and `.sort_index()`\n"]},{"cell_type":"code","metadata":{"id":"iLJGUXbfC7Ef","colab_type":"code","colab":{}},"source":["# Using .reindex() vs Using .sort_index()\n","ordered = ['Jan', 'Apr', 'Jul', 'Oct']\n","w_mean2 = w_mean.reindex(ordered) # Order by the specific order, according to the list\n","w_mean2.sort_index() # Order according to the values in the index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RBcSh1fcEcdW","colab_type":"code","colab":{}},"source":["# Sorting\n","weather1 = pd.read_csv('monthly_max_temp.csv', index_col='Month')\n","weather2 = weather1.sort_index()\n","weather3 = weather1.sort_index(ascending=False)\n","weather4 = weather1.sort_values('Max TemperatureF')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oxWKbk7xCUNY","colab_type":"text"},"source":["### Reindex from a DataFrame Index"]},{"cell_type":"code","metadata":{"id":"3lvZTWDHDEHi","colab_type":"code","colab":{}},"source":["# Using reindex\n","w_mean.reindex(w_max.index).dropna() \n","\n","\"\"\"\n","Order by the index of DataFrame w_max and drop rows that could have \n","been created during the process\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lpEYVTKFCafH","colab_type":"text"},"source":["### Reindexing with missing labels"]},{"cell_type":"code","metadata":{"id":"T74GT0qiCcIN","colab_type":"code","colab":{}},"source":["w_mean3 = w_mean.reindex(['Jan', 'Apr', 'Dec'])\n","print(w_mean3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1UkX64iwUnL4","colab_type":"code","colab":{}},"source":["# Reindex and forward-fill\n","weather1 # Has just months 'Jan', 'Apr', 'Jul' and 'Oct'\n","year # Has all the months of the year\n","weather2 = weather1.reindex(year) # Will create 8 more rows, for those months that are not in weather1. New rows will get value NaN\n","weather3 = weather1.reindex(year).ffill() # Forward-fill cells with NaN value. Repeat the value of the antecedent row/cell"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r_qDlX75E1qR","colab_type":"text"},"source":["## Arithmetic with Series & DataFrames"]},{"cell_type":"markdown","metadata":{"id":"VCYN4A-QFA2L","colab_type":"text"},"source":["### Scalar multiplication"]},{"cell_type":"code","metadata":{"id":"LOsy8kW_FDry","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","weather = pd.read_csv('pittsburgh2013.csv', index_col='Date', \n","                      parse_dates=True) # With parse_dates=True we get datetime objects\n","\n","weather.loc['2013-07-01':'2013-07-07', 'PrecipitationIn'] * 2.54"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x2g5XHY2FbkD","colab_type":"text"},"source":["### Division and Percentage"]},{"cell_type":"code","metadata":{"id":"x5QVjMHeFdBL","colab_type":"code","colab":{}},"source":["# Absolute temperature range\n","week1_range = weather.loc['2013-07-01':'2013-07-07',\n","                          ['Min TemperatureF', 'Max TemperatureF']]\n","\n","# Average temperature\n","week1_mean = weather.loc['2013-07-01':'2013-07-07',\n","                         'Mean TemperatureF']\n","\n","# Division\n","week1_range.divide(week1_mean, axis='rows')\n","\n","# Percentage change\n","week1_mean.pct_change() * 100 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KCtVmLSiF6Eg","colab_type":"text"},"source":["### Study Case: Olympic medals"]},{"cell_type":"markdown","metadata":{"id":"wxyRFBtIGGn6","colab_type":"text"},"source":["#### Using the `.add()` method and `fill_value`"]},{"cell_type":"code","metadata":{"id":"5qoqUHUdUsFe","colab_type":"code","colab":{}},"source":["# Addition\n","bronze = pd.read_csv('bronze_top5.csv', index_col=0)\n","silver = pd.read_csv('silver_top5.csv', index_col=0)\n","gold = pd.read_csv('gold_top5.csv', index_col=0)\n","bronze.add(silver, fill_value=0) # Add two dataframes. fill_value=0 to avoid NaN values\n","bronze.add(silver, fill_value=0).add(gold, fill_value=0) # Add three datagrames\n","\n","# Example 1\n","gdp = pd.read_csv('GDP.csv', index_col='DATE', parse_dates=True)\n","post2008 = gdp.loc['2008':,:] # Slice all the gdp data from 2008 onward\n","print(post2008.tail(8)) # Print the last 8 rows of post2008\n","yearly = post2008.resample('A').last() # Gets sample from annual frequency ('A') and get the last element of each year\n","yearly['growth'] = yearly.pct_change() * 100 # Compute percentage growth of yearly: yearly['growth']\n","\n","# Example 2\n","sp500 = pd.read_csv('sp500.csv')\n","exchange = pd.read_csv('exchange.csv')\n","dollars = sp500[['Open', 'Close']] # Subset 'Open' & 'Close' columns\n","print(dollars.head())\n","pounds = dollars.multiply(exchange['GBP/USD'], axis='rows') # Convert dollars to pounds\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IxsG_7BbRCFe","colab_type":"text"},"source":["# Chapter 2 - Concatenating data\n","\n","You'll learn how to perform database-style operations to combine DataFrames. In particular, you'll learn about appending and concatenating DataFrames while working with a variety of real-world datasets."]},{"cell_type":"markdown","metadata":{"id":"luEh63r7RLlU","colab_type":"text"},"source":["## Appending and concatenating Series"]},{"cell_type":"markdown","metadata":{"id":"sRS6qSLfRj3Y","colab_type":"text"},"source":["### `.concat()` and `.append()`"]},{"cell_type":"code","metadata":{"id":"bZSRfaMDiR2g","colab_type":"code","colab":{}},"source":["# Appending & concatenating Series\n","result1 = pd.concat([s1, s2, s3])\n","result2 = s1.append(s2).append(s3)\n","result1 == result2 elementwise\n","\n","import pandas as pd\n","northeast = pd.Series(['CT', 'ME', 'MA', 'NH', 'RI', 'VT', 'NJ', 'NY', 'PA'])\n","south = pd.Series(['DE', 'FL', 'GA', 'MD', 'NC', 'SC', 'VA', 'DC', 'WV', 'AL', 'KY', 'MS', 'TN', 'AR', 'LA', 'OK', 'TX'])\n","midwest = pd.Series(['IL', 'IN', 'MN', 'MO', 'NE', 'ND', 'SD', 'IA', 'KS', 'MI', 'OH', 'WI'])\n","west = pd.Series(['AZ', 'CO', 'ID', 'MT', 'NV', 'NM', 'UT', 'WY', 'AK', 'CA', 'HI', 'OR','WA'])\n","\n","# Append \n","east = northeast.append(south) # Has repeated indeces\n","new_east = northeast.append(south).reset_index(drop=True) # Create new index without any repeated indice\n","\n","# Concat\n","east = pd.concat([northeast, south]) # Has repeated indices\n","new_east = pd.concat([northeast, south], ignore_index=True) # Create new index without repeated indices\n","new_east = pd.concat([northeast, south], axis=0) # Concatenate rows. axis=0 to concatenated 'south' in the bottom of 'northeast'\n","new_east = pd.concat([northeast, south], axis=1) # Concatenate columns. Equal indices create just one row in the final table"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CPFNjuNVRvsS","colab_type":"text"},"source":["## Appending and concatenating DataFrames"]},{"cell_type":"code","metadata":{"id":"Ja6yK1KeRrYT","colab_type":"code","colab":{}},"source":["medal = []\n","gold = pd.read_csv('gold.csv', header=0, index_col='Country', names=columns)\n","silver = pd.read_csv('silver.csv', header=0, index_col='Country', names=columns)\n","medals.append(gold).append(silver) # Create list with gold and silver\n","medals_df = pd.concat(medals, axis='columns') # Concatenate medals horizontally: medals_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"07OM4awjSHFO","colab_type":"text"},"source":["## Concatenation, keys, and MultiIndexes"]},{"cell_type":"code","metadata":{"id":"qdm6TVP9XlDy","colab_type":"code","colab":{}},"source":["# Loading rainfall data\n","rain2013 = pd.read_csv(\"railfall2013.csv\", \n","                       index_col='Month', \n","                       parse_dates=True) \n","rain2014 = pd.read_csv(\"railfall2014.csv\", \n","                       index_col='Month', \n","                       parse_dates=True) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P_IfyiBpSZpG","colab_type":"text"},"source":["### Concatenating rows"]},{"cell_type":"code","metadata":{"id":"gqy5x1URSUUP","colab_type":"code","colab":{}},"source":["# Concatenating rows\n","rain1314 = pd.concat([rain2013, rain2014], axis=0) # Create repeated indeces, but each month is from a different year\n","rain1314 = pd.concat([rain2013, rain2014], keys=[2013, 2014], axis=0) # Creates an outer indix level with the year associated with each month\n","print(rain1314.loc[2014]) # Access results from year 2014"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yFHUBAOGScn4","colab_type":"text"},"source":["### Using multi-index on rows"]},{"cell_type":"code","metadata":{"id":"iJfYYOMcShBA","colab_type":"code","colab":{}},"source":["rain1314 = pd.concat([rain2013, rain2014], keys=[2013, 2014], axis='columns') # Created multi-index in column level"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eLup0IOoS-_u","colab_type":"text"},"source":["### `pd.concat()` with dict"]},{"cell_type":"code","metadata":{"id":"Ue8lcDRJTCjK","colab_type":"code","colab":{}},"source":["rain_dict = {2013: rain2013, 2014: rain2014}\n","rain1314 = pd.concat(rain_dict, axis='columns')\n","print(rain1314)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"onPzv7zsS4Kl","colab_type":"text"},"source":["## Exercise"]},{"cell_type":"code","metadata":{"id":"h9f6rrOSS2RE","colab_type":"code","colab":{}},"source":["# Example 1\n","bronze = pd.read_csv('bronze.csv', index_col='Country')\n","silver = pd.read_csv('silver.csv', index_col='Country')\n","gold = pd.read_csv('gold.csv', index_col='Country')\n","\n","medals.append(gold).append(silver).append(silver) \n","medals = pd.concat(medals, keys=['bronze', 'silver', 'gold'])\n","medals_sorted = medals.sort_index(level=0) # Sort the entries of medals: medals_sorted\n","\n","print(medals_sorted.loc[('bronze','Germany')]) # Print the number of Bronze medals won by Germany\n","print(medals_sorted.loc['silver']) # Print data about silver medals\n","idx = pd.IndexSlice # Create alias 'idex' for pd.IndexSlice. A slicer pd.IndexSlice is required when slicing on the inner level of a MultiIndex.\n","print(medals_sorted.loc[idx[:,'United Kingdom'], :]) # Print all the data on medals won by the United Kingdom"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"792uudXHS91U","colab_type":"code","colab":{}},"source":["# Example 2\n","month_list = [('january', jan), ('february', feb), ('march', mar)]\n","month_dict = {} # Create dictionary\n","for month_name, month_data in month_list:\n","    month_dict[month_name] = month_data.groupby('Company').sum() # Group month_data by 'Company'\n","sales = pd.concat(month_dict) # Concatenate data in month_dict: sales\n","idx = pd.IndexSlice \n","print(sales.loc[idx[:, 'Mediacore'], :]) # Print all sales by Mediacore"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HRrVqvHnTMyP","colab_type":"text"},"source":["## Outer and inner joins\n","\n","* Joining tables: Combining rows of multiple tables\n","\n","* Outer join\n","  * **Union** of index sets (all labels, no repetition)\n","  * Missing fields filled with NaN\n","\n","* Inner join\n","  * **Intersection** of index sets (only common labels)"]},{"cell_type":"code","metadata":{"id":"_QxwnINtLDRQ","colab_type":"code","colab":{}},"source":["# Outer & inner joins\n","import pandas as pd\n","pd.concat([population, unemployment], axis=1, join='inner') # Has just the columns of both sets\n","pd.concat([population, unemployment], axis=1, join='outer') # Has the columns of all sets"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y5vZrGUlU7s4","colab_type":"text"},"source":["## Exercise"]},{"cell_type":"code","metadata":{"id":"DW7ks-ziU4ut","colab_type":"code","colab":{}},"source":["# Example\n","china_annual = china.resample('A').last().pct_change(10).dropna()\n","us_annual = us.resample('A').last().pct_change(10).dropna()\n","gdp = pd.concat([china_annual, us_annual], join='inner', axis=1) # Concatenate china_annual and us_annual\n","print(gdp.resample('10A').last()) # Resample 10 years (annual) gdp and print"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w03QbaIsU_c4","colab_type":"text"},"source":["# Chapter 3 - Merging data\n","\n","You'll learn all about merging pandas DataFrames. You'll explore different techniques for merging, and learn about left joins, right joins, inner joins, and outer joins, as well as when to use which. You'll also learn about ordered merging, which is useful when you want to merge DataFrames with columns that have natural orderings, like date-time columns."]},{"cell_type":"markdown","metadata":{"id":"vbNuAMnUVKjE","colab_type":"text"},"source":["## Mergind DataFrames"]},{"cell_type":"code","metadata":{"id":"l0LC-67iVbKN","colab_type":"code","colab":{}},"source":["# Simple merge\n","import pandas as pd\n","\n","population = pd.read_csv('pa_zipcode_population.csv')\n","cities = pd.read_csv('pa_zipcode_city.csv')\n","\n","pd.merge(population, cities)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3WdEX7ljVmA0","colab_type":"text"},"source":["### Merging all columns"]},{"cell_type":"code","metadata":{"id":"MDyTYmYEVqNn","colab_type":"code","colab":{}},"source":["bronze = pd.read_csv('bronze_sorted.csv')\n","gold = pd.read_csv('gold_sorted.csv')\n","pd.merge(bronze, gold)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IIEJ0Q42V_xM","colab_type":"text"},"source":["### Merging on\n","\n","* One column\n","* Multiple columns"]},{"cell_type":"code","metadata":{"id":"52Pv9Jv3WCS5","colab_type":"code","colab":{}},"source":["# Merging on one column\n","pd.merge(bronze, gold, on='NOC')\n","'''Both DataFrames have exactly the same columns. So a columns is \n","specified to be examinated for the merge ('NOC'). Columns 'country' is \n","repeated in the final merge. '''\n","\n","# Merging on multiple columns\n","pd.merge(bronze, gold, on=['NOC', 'Country']) \n","'''Merge both DataFrames by columns 'NOC' and 'Contry'. The result is\n","a DataFrame with columns 'NOC', 'Country', 'Total_x' and 'Total_y' '''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IMpLVheYWRDT","colab_type":"text"},"source":["### Using suffixes"]},{"cell_type":"code","metadata":{"id":"bT901D5kWTfi","colab_type":"code","colab":{}},"source":["pd.merge(bronze, gold, on=['NOC', 'Country'], suffixes=['_bronze', '_gold'])\n","'''Changes sufixes 'Total_x' and 'Total_y' for 'Total_bronze'\n","and 'Total_gold' '''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ivdcciTgWc2t","colab_type":"text"},"source":["### Specifying columns to merge"]},{"cell_type":"code","metadata":{"id":"1pmVnhvlL5FE","colab_type":"code","colab":{}},"source":["pd.merge(counties, cities, left_on='CITY NAME', right_on='City')\n","'''Works like a inner join, merging only the columns that occur \n","in both DataFrames. A new row is made for each entry that is in\n","the columns of both DataFrames, merging all other columns.'''\n","\n","pd.merge(counties, cities, left_on='CITY NAME', right_on='City')\n","'''Merge DataFrames with different columns names. Column names are\n","specified. left_on for DataFrame 'counties' and right_on for DataFrame\n","'cities'. '''\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G9ep0d2Swm5b","colab_type":"text"},"source":["## Joining DataFrames"]},{"cell_type":"markdown","metadata":{"id":"ATIwvpWZXa12","colab_type":"text"},"source":["### Merging with inner join"]},{"cell_type":"code","metadata":{"id":"atJQdP6wXTU1","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","bronze = pd.read_csv('bronze_sorted.csv')\n","gold = pd.read_csv('gold_sorted.csv')\n","\n","pd.merge(bronze, gold, on=['NOC', 'Country'], \n","         suffixes=['_bronze', '_gold'],\n","         how='inner')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iAjBYp0tXnHw","colab_type":"text"},"source":["### Merging with left join\n","\n","* Keeps all rows of the left DF in the merged DF\n","* For rows in the left DF with matches in the right DF:\n","> Non-joining columns of right DF are appended to left DF\n","* For rows in the left DF with no matches in the right DF:\n","> Non-joining columns are filled with nulls"]},{"cell_type":"code","metadata":{"id":"NC24WisnXxWr","colab_type":"code","colab":{}},"source":["pd.merge(bronze, gold, on=['NOC', 'Country'], \n","         suffixes=['_bronze', '_gold'],\n","         how='left')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lsjERdFgX7Ym","colab_type":"text"},"source":["### Merging with right join\n"]},{"cell_type":"code","metadata":{"id":"hSRjfsmrYBFu","colab_type":"code","colab":{}},"source":["pd.merge(bronze, gold, on=['NOC', 'Country'], \n","         suffixes=['_bronze', '_gold'],\n","         how='right')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WZ0DmF32YNnQ","colab_type":"text"},"source":["### Merging with outer join"]},{"cell_type":"code","metadata":{"id":"N7ZsGrb-YRI4","colab_type":"code","colab":{}},"source":["pd.merge(bronze, gold, on=['NOC', 'Country'], \n","         suffixes=['_bronze', '_gold'],\n","         how='outer')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"toZYg2IiYVN3","colab_type":"text"},"source":["### Using `.join`\n","\n","* .join(how=\"left\")\n","* .join(how=\"right\")\n","* .join(how=\"inner\")\n","* .join(how=\"outer\")"]},{"cell_type":"code","metadata":{"id":"PY79O6KwYkAJ","colab_type":"code","colab":{}},"source":["population = pd.read_csv('population_00.csv', index_col=0)\n","unemployment = pd.read_csv('unemployment_00.csv', index_col=0)\n","\n","population.join(unemployment) # how=\"left\"\n","population.join(unemployment, how='right')\n","population.join(unemployment, how='inner')\n","population.join(unemployment, how='outer')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Hj3kDtjY3jP","colab_type":"text"},"source":["### Which should you use?\n","\n","* `df1.append(df2)` : stacking vertically\n","* `pd.concat([df1, df2])` :\n","  * stacking many horizontally or vertically\n","  * simple inner/outer joins on Indexes\n","* `df1.join(df2)` : inner/outer/left/right joins on Indexes\n","* `pd.merge([df1, df2])` : many joins on multiple columns\n"]},{"cell_type":"markdown","metadata":{"id":"WqRaTcpaZGuJ","colab_type":"text"},"source":["## Ordered merges"]},{"cell_type":"code","metadata":{"id":"1TIuZHlwZMXK","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","software = pd.read_csv('feb-sales-Software.csv',\n","                       parse_dates=['Date']).sort_values('Date')\n","\n","hardware = pd.read_csv('feb-sales-Hardware.csv',\n","                       parse_dates=['Date']).sort_values('Date')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"INqSOYC3ZjLI","colab_type":"text"},"source":["### Using `merge(how='outer')` and `sorted_values()`"]},{"cell_type":"code","metadata":{"id":"pm8lKuxn6CEp","colab_type":"code","colab":{}},"source":["pd.merge(hardware, software,\n","         how='outer').sorted_values('Date')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0RYMSexmZ9PR","colab_type":"text"},"source":["### Using `merge_ordered()`\n","\n","* Does a merge outer join and order values"]},{"cell_type":"code","metadata":{"id":"-19atYm8aAYO","colab_type":"code","colab":{}},"source":["pd.merge_ordered(hardware, software)\n","\n","pd.merge_ordered(hardware, software, on=['Date', 'Company'],\n","                 suffixes=['_hardware', '_software'])\n","\n","pd.merge_ordered(hardware, software, on=['Date', 'Company'],\n","                 suffixes=['_hardware', '_software'], \n","                 fill_method='ffill') # Add forward-fill"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1iJXGCGQmFxc","colab_type":"text"},"source":["# Chapter 4 - Case Study - Summer Olympics \n","* Course Final Exercise"]},{"cell_type":"markdown","metadata":{"id":"98v_nn0bbCyG","colab_type":"text"},"source":["## Creating DataFrames of Summer Olympics Medals"]},{"cell_type":"code","metadata":{"id":"Jy3hXaXbmREA","colab_type":"code","colab":{}},"source":["# ----------------------------------------------------------------------\n","# Creating DataFrames of Summer Olympics Medals\n","# ----------------------------------------------------------------------\n","import pandas as pd\n","\n","file_path = 'Summer Olympic medallists 1896 to 2008 - EDITIONS.tsv'\n","editions = pd.read_csv(file_path, sep='\\t')\n","editions = editions[['Edition', 'Grand Total', 'City', 'Country']] # Extract the relevant columns\n","print(editions)\n","\n","file_path = 'Summer Olympic medallists 1896 to 2008 - IOC COUNTRY CODES.csv'\n","ioc_codes = pd.read_csv(file_path) # Load DataFrame from file_path\n","ioc_codes = ioc_codes[['Country', 'NOC']] # Extract the relevant columns\n","print(ioc_codes.head())\n","print(ioc_codes.tail())\n","\n","medals_dict = {} # Create empty dictionary\n","for year in editions['Edition']:\n","    file_path = 'summer_{:d}.csv'.format(year)  \n","    medals_dict[year] = pd.read_csv(file_path) # Load file_path into a DataFrame\n","    medals_dict[year] = medals_dict[year][['Athlete', 'NOC', 'Medal']] # Extract relevant columns    \n","    medals_dict[year]['Edition'] = year # Assign year to column 'Edition'\n","medals = pd.concat(medals_dict, ignore_index=True) # Concatenate medals_dict\n","print(medals.head())\n","print(medals.tail())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X3eh-0eCbIyX","colab_type":"text"},"source":["## Extracting Quantitative Measurements"]},{"cell_type":"code","metadata":{"id":"lJi-fiO6bI7V","colab_type":"code","colab":{}},"source":["# ----------------------------------------------------------------------\n","# Extracting Quantitative Measurements\n","# ----------------------------------------------------------------------\n","import pandas as pd \n","\n","medal_counts = pd.pivot_table(medals, aggfunc='count', index='Edition', values='Athlete', columns='NOC')\n","print(medal_counts.head())\n","print(medal_counts.tail())\n","\n","totals = editions.set_index('Edition') # Set Index of editions\n","totals = totals['Grand Total'] # Reassign totals['Grand Total']\n","fractions = medal_counts.divide(totals, axis='rows') # Divide medal_counts by totals\n","print(fractions.head())\n","print(fractions.tail())\n","\n","mean_fractions = fractions.expanding().mean() # Apply the expanding mean\n","fractions_change = mean_fractions.pct_change()*100 # Compute the percentage change\n","fractions_change = fractions_change.reset_index('Edition') # Reset the index of fractions_change\n","print(fractions_change.head())\n","print(fractions_change.tail())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kfxl4k3AbNNk","colab_type":"text"},"source":["## Reshaping and Plotting"]},{"cell_type":"code","metadata":{"id":"NexW0vDlbNb1","colab_type":"code","colab":{}},"source":["# ----------------------------------------------------------------------\n","# Reshaping and Plotting\n","# ----------------------------------------------------------------------\n","import pandas as pd\n","\n","hosts = pd.merge(editions, ioc_codes, how='left') # Left join editions and ioc_codes\n","hosts = hosts[['Edition', 'NOC']].set_index('Edition') # Extract relevant columns and set index\n","print(hosts.loc[hosts.NOC.isnull()]) # Fix missing 'NOC' values of hosts\n","hosts.loc[1972, 'NOC'] = 'FRG'\n","hosts.loc[1980, 'NOC'] = 'URS'\n","hosts.loc[1988, 'NOC'] = 'KOR'\n","hosts = hosts.reset_index() # Reset Index of hosts\n","print(hosts)\n","\n","reshaped = pd.melt(fractions_change, id_vars='Edition', value_name='Change') # Reshape fractions_change\n","print(reshaped.shape, fractions_change.shape)\n","chn = reshaped[reshaped['NOC'] == 'CHN'] # Extract rows from reshaped where 'NOC' == 'CHN'\n","print(chn.tail())\n","\n","'''\n","Conclusion: On looking at the hosting countries from the last 5 Olympic \n","editions and the fractional change of medals won by China the last 5 \n","editions, you can see that China fared significantly better in 2008\n","(i.e., when China was the host country).\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iH6CngI0bQ_t","colab_type":"text"},"source":["## Merging to compute influence"]},{"cell_type":"code","metadata":{"id":"V5tOYMKgbRH3","colab_type":"code","colab":{}},"source":["# ----------------------------------------------------------------------\n","# Merging to compute influence\n","# ----------------------------------------------------------------------\n","merged = pd.merge(reshaped, hosts, how='inner') \n","print(merged.head())\n","influence = merged.set_index('Edition').sort_index()\n","print(influence.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1NnEaT_9bbLV","colab_type":"text"},"source":["## Customize the plot to improve readability"]},{"cell_type":"code","metadata":{"id":"O76nzM47bbT_","colab_type":"code","colab":{}},"source":["# ----------------------------------------------------------------------\n","# Customize the plot to improve readability\n","# ----------------------------------------------------------------------\n","import matplotlib.pyplot as plt\n","change = influence['Change']\n","ax = change.plot(kind='bar') # Bar plot\n","\n","ax.set_ylabel(\"% Change of Host Country Medal Count\")\n","ax.set_title(\"Is there a Host Country Advantage?\")\n","ax.set_xticklabels(editions['City'])\n","plt.show()"],"execution_count":null,"outputs":[]}]}